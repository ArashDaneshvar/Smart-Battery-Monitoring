{"cells":[{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928592714,"execution_millis":3224,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":1},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":false,"deepnote_app_is_output_hidden":true,"cell_id":"8eea9242e71a40ecbf50a7f5048d3966","deepnote_cell_type":"code"},"source":"import tensorflow as tf","block_group":"9cd121d8fa5f4b808f4b39583b2d233c","execution_count":null,"outputs":[{"name":"stderr","text":"2023-09-05 15:43:13.027986: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-09-05 15:43:13.116918: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-09-05 15:43:13.118130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-09-05 15:43:14.355636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/50f32bdf-5d1a-415e-8f48-f6cfeff6ee15","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"6067c3947b904e5295b048269000c774","deepnote_cell_type":"markdown"},"source":"# Define Hyper-Parameters","block_group":"0f38b608cf744350ba27896ca79b4d13"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928595942,"execution_millis":6,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":29},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"ea85854515c6455ba2ce76dd86a5a1b9","deepnote_cell_type":"code"},"source":"PREPROCESSING_ARGS = {\n    'sampling_rate': 16000,\n    'frame_length_in_s': 0.04,\n    'frame_step_in_s': 0.02,\n    'num_mel_bins': 40,\n    'lower_frequency': 20,\n    'upper_frequency': 4000,\n}\n\nTRAINING_ARGS = {\n    'batch_size': 20,\n    'initial_learning_rate': 0.01,\n    'end_learning_rate': 1.e-5,\n    'epochs': 10\n}\n\nfinal_sparsity = 0.70","block_group":"384a855cd83d42ac91fd57dc350163fa","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":41},"deepnote_app_block_visible":true,"cell_id":"9f8d39b55691455084042e2b5f7c42d1","deepnote_cell_type":"markdown"},"source":"# Create Train/Val/Test Datasets","block_group":"0bee752ec35f4216b535a0afd971283f"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928598104,"execution_millis":472,"deepnote_app_coordinates":{"h":27,"w":12,"x":0,"y":46},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"64738917287840369f7076f5c5fb775b","deepnote_cell_type":"code"},"source":"train_ds = tf.data.Dataset.list_files('msc-train/*')\nval_ds = tf.data.Dataset.list_files('msc-val/*')\ntest_ds = tf.data.Dataset.list_files('msc-test/*')","block_group":"8ec043bb3175423aa2ca6824aaa2c760","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tf' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsc-train/*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsc-val/*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsc-test/*\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/f78693ea-99d1-405c-a695-168fdc8aa34a","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928603495,"execution_millis":1186,"deepnote_app_coordinates":{"h":24,"w":12,"x":0,"y":74},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"0166bea7f8434d0190f6db4c2ea8e908","deepnote_cell_type":"code"},"source":"from preprocessing import LABELS\nfrom preprocessing import AudioReader\nfrom preprocessing import MelSpectrogram\n\n\naudio_reader = AudioReader(tf.int16, 16000)\nmel_spec_processor = MelSpectrogram(**PREPROCESSING_ARGS)\n\ndef prepare_for_training(feature, label):\n    feature = tf.expand_dims(feature, -1)\n    label_id = tf.argmax(label == LABELS)\n\n    return feature, label_id\n\n\nbatch_size = TRAINING_ARGS['batch_size']\nepochs = TRAINING_ARGS['epochs']\n\ntrain_ds = (train_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mel_spec_processor.get_mel_spec_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size)\n            .cache())\nval_ds = (val_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mel_spec_processor.get_mel_spec_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size))\ntest_ds = (test_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mel_spec_processor.get_mel_spec_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size))","block_group":"1333b7e0ac0544ed9d129db98698685a","execution_count":null,"outputs":[{"name":"stderr","text":"2023-09-05 15:43:23.857396: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n2023-09-05 15:43:23.857560: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX AVX2 AVX512F FMA\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/35222f7d-549d-45a6-b283-a316f97dae04","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928616007,"execution_millis":487,"deepnote_app_coordinates":{"h":9,"w":12,"x":0,"y":99},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"90f9a2cd2b8d4e818c5236c196084529","deepnote_cell_type":"code"},"source":"for example_batch, example_labels in train_ds.take(1):\n  print('Batch Shape:', example_batch.shape)\n  print('Data Shape:', example_batch.shape[1:])\n  print('Labels:', example_labels)","block_group":"70e732efd1d34350b58375211a92c0bb","execution_count":null,"outputs":[{"name":"stdout","text":"Batch Shape: (20, 49, 40, 1)\nData Shape: (49, 40, 1)\nLabels: tf.Tensor([0 4 4 1 3 3 7 3 2 1 2 2 3 3 7 2 5 5 5 2], shape=(20,), dtype=int64)\n2023-09-05 15:43:36.389536: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/35abf739-dedf-442b-9901-59246cc65f04","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":123},"deepnote_app_block_visible":true,"cell_id":"1a7cd4734f1e4e4e9784e8e0555f431a","deepnote_cell_type":"markdown"},"source":"# Create the Model","block_group":"30ea73c549884a928dece67cbcf50124"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"fb9079e5e55a4db3adc74fb830068b86","deepnote_cell_type":"markdown"},"source":"\nConv2D(filters=128, kernel_size=[3, 3], stride=[2, 2], use_bias=False, padding=’valid’)\nBatchNormalization()\nReLU()\nConv2D(filters=128, kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding=’same’)\nBatchNormalization()\nReLU()\nConv2D(filters=128, kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding=’same’)\nBatchNormalization()\nReLU()\nGlobalAveragePooling2D()\nDense(units=8)\nSoftmax()\n","block_group":"3f252ddadd824a549e8ec30ff0ca85d3"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928619149,"execution_millis":98,"deepnote_app_coordinates":{"h":13,"w":12,"x":0,"y":109},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"d7e317377f554d17a8ceb54fb1f02437","deepnote_cell_type":"code"},"source":"model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n    tf.keras.layers.Conv2D(filters=128, kernel_size=[3, 3], strides=[2, 2], use_bias=False, padding='valid'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=128, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=128, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(units=len(LABELS)),\n    tf.keras.layers.Softmax()\n])","block_group":"bc4acde6c8b94a849a6935a167208539","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":0},"deepnote_app_block_visible":true,"cell_id":"a9f5a14ddd7d4c118944b3c79a58a076","deepnote_cell_type":"markdown"},"source":"# Setup Magnitude-based Weights Pruning","block_group":"36dd1b6369a94ac4b5071a35ef057d93"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928622280,"execution_millis":776,"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":0},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"bb9911479672485eb9e1ab7f98fc44a2","deepnote_cell_type":"code"},"source":"import tensorflow_model_optimization as tfmot\n\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n\nbegin_step = int(len(train_ds) * epochs * 0.2)\nend_step = int(len(train_ds) * epochs)\n\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.20,\n        final_sparsity=final_sparsity,\n        begin_step=begin_step,\n        end_step=end_step\n    )\n}\n\nmodel_for_pruning = prune_low_magnitude(model, **pruning_params)","block_group":"66f930825aa7418db276fe0fd8de78c1","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928624719,"execution_millis":286,"deepnote_app_coordinates":{"h":27,"w":12,"x":0,"y":141},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"9ccaadcbc2b54bb4a0f5a35340d7971f","deepnote_cell_type":"code"},"source":"model_for_pruning.summary()","block_group":"05bdfcabbd4d4db49c53e0e61c019656","execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n prune_low_magnitude_conv2d  (None, 24, 19, 128)       2306      \n  (PruneLowMagnitude)                                            \n                                                                 \n prune_low_magnitude_batch_  (None, 24, 19, 128)       513       \n normalization (PruneLowMag                                      \n nitude)                                                         \n                                                                 \n prune_low_magnitude_re_lu   (None, 24, 19, 128)       1         \n (PruneLowMagnitude)                                             \n                                                                 \n prune_low_magnitude_conv2d  (None, 24, 19, 128)       294914    \n _1 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 24, 19, 128)       513       \n normalization_1 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 24, 19, 128)       1         \n 1 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_conv2d  (None, 24, 19, 128)       294914    \n _2 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 24, 19, 128)       513       \n normalization_2 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 24, 19, 128)       1         \n 2 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_global  (None, 128)               1         \n _average_pooling2d (PruneL                                      \n owMagnitude)                                                    \n                                                                 \n prune_low_magnitude_dense   (None, 8)                 2058      \n (PruneLowMagnitude)                                             \n                                                                 \n prune_low_magnitude_softma  (None, 8)                 1         \n x (PruneLowMagnitude)                                           \n                                                                 \n=================================================================\nTotal params: 595736 (2.27 MB)\nTrainable params: 297864 (1.14 MB)\nNon-trainable params: 297872 (1.14 MB)\n_________________________________________________________________\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/035019f4-37e7-427e-98cf-32cce65cb322","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":169},"deepnote_app_block_visible":true,"cell_id":"34767ca1451642dbac0c443cf81e4e64","deepnote_cell_type":"markdown"},"source":"# Train the Model","block_group":"1eea9dabb65943679014e2544dbe9581"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928627349,"execution_millis":1662367,"deepnote_app_coordinates":{"h":29,"w":12,"x":0,"y":174},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"c09cec93ea694756b3c8b4c85769b8ac","deepnote_cell_type":"code"},"source":"loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\ninitial_learning_rate = TRAINING_ARGS['initial_learning_rate']\nend_learning_rate = TRAINING_ARGS['end_learning_rate']\n\nlinear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate=initial_learning_rate,\n    end_learning_rate=end_learning_rate,\n    decay_steps=len(train_ds) * epochs,\n)\noptimizer = tf.optimizers.Adam(learning_rate=linear_decay)\nmetrics = [tf.metrics.SparseCategoricalAccuracy()]\ncallbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\nmodel_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\nhistory = model_for_pruning.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)","block_group":"e23e1c8641d84889aa09957711d08618","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n320/320 [==============================] - 246s 754ms/step - loss: 1.9533 - sparse_categorical_accuracy: 0.2300 - val_loss: 1.8354 - val_sparse_categorical_accuracy: 0.2788\nEpoch 2/10\n320/320 [==============================] - 149s 466ms/step - loss: 1.4109 - sparse_categorical_accuracy: 0.4748 - val_loss: 1.5679 - val_sparse_categorical_accuracy: 0.4725\nEpoch 3/10\n320/320 [==============================] - 149s 465ms/step - loss: 0.9528 - sparse_categorical_accuracy: 0.6644 - val_loss: 0.9830 - val_sparse_categorical_accuracy: 0.6600\nEpoch 4/10\n320/320 [==============================] - 151s 471ms/step - loss: 0.7019 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.8012\nEpoch 5/10\n320/320 [==============================] - 168s 524ms/step - loss: 0.5569 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.6253 - val_sparse_categorical_accuracy: 0.7962\nEpoch 6/10\n320/320 [==============================] - 152s 474ms/step - loss: 0.4760 - sparse_categorical_accuracy: 0.8498 - val_loss: 0.5737 - val_sparse_categorical_accuracy: 0.8138\nEpoch 7/10\n320/320 [==============================] - 152s 475ms/step - loss: 0.4168 - sparse_categorical_accuracy: 0.8672 - val_loss: 0.7122 - val_sparse_categorical_accuracy: 0.7812\nEpoch 8/10\n320/320 [==============================] - 148s 462ms/step - loss: 0.3684 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.8275\nEpoch 9/10\n320/320 [==============================] - 148s 462ms/step - loss: 0.3320 - sparse_categorical_accuracy: 0.8973 - val_loss: 0.4099 - val_sparse_categorical_accuracy: 0.8687\nEpoch 10/10\n320/320 [==============================] - 148s 462ms/step - loss: 0.3044 - sparse_categorical_accuracy: 0.9116 - val_loss: 0.3840 - val_sparse_categorical_accuracy: 0.8775\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/970e879d-7dd2-4394-ae6d-1830a1c05a60","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693930289725,"execution_millis":263,"deepnote_app_coordinates":{"h":28,"w":12,"x":0,"y":204},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"b6c1a8d3d63742c7804a93f79186c6d6","deepnote_cell_type":"code"},"source":"history.history","block_group":"df89f8bc24e44d798173bba7945567b7","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"{'loss': [1.953321933746338,\n  1.4109406471252441,\n  0.9527828097343445,\n  0.7018911242485046,\n  0.5568985939025879,\n  0.476011723279953,\n  0.4168280363082886,\n  0.36837804317474365,\n  0.33201244473457336,\n  0.30442625284194946],\n 'sparse_categorical_accuracy': [0.23000000417232513,\n  0.47484374046325684,\n  0.6643750071525574,\n  0.7659375071525574,\n  0.8154687285423279,\n  0.8498437404632568,\n  0.8671875,\n  0.8884375095367432,\n  0.8973437547683716,\n  0.9115625023841858],\n 'val_loss': [1.835437297821045,\n  1.567899465560913,\n  0.9830249547958374,\n  0.6669675707817078,\n  0.6253290176391602,\n  0.5737168788909912,\n  0.7121668457984924,\n  0.5369672179222107,\n  0.40990573167800903,\n  0.384001761674881],\n 'val_sparse_categorical_accuracy': [0.2787500023841858,\n  0.4724999964237213,\n  0.6600000262260437,\n  0.8012499809265137,\n  0.7962499856948853,\n  0.8137500286102295,\n  0.78125,\n  0.8274999856948853,\n  0.8687499761581421,\n  0.8774999976158142]}"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/19f37ba4-ac70-40f7-b417-b499f0fcb61d","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693930624843,"execution_millis":132,"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":0},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"ca5dbbf0d04e4b93897399cbf5633d84","deepnote_cell_type":"code"},"source":"import numpy as np\n\n\nfor layer in model_for_pruning.layers:\n    if isinstance(layer, tf.keras.layers.Wrapper):\n        weights = layer.trainable_weights\n    else:\n        weights = layer.weights\n    for weight in weights:        \n        weight_size = weight.numpy().size\n        zero_num = np.count_nonzero(weight == 0)\n        print(\n            f'{weight.name}: {zero_num/weight_size:.2%} sparsity ',\n            f'({zero_num}/{weight_size})',\n        )","block_group":"9b858f04c36844329f63f0680184f055","execution_count":null,"outputs":[{"name":"stdout","text":"conv2d/kernel:0: 69.97% sparsity  (806/1152)\nbatch_normalization/gamma:0: 0.00% sparsity  (0/128)\nbatch_normalization/beta:0: 0.00% sparsity  (0/128)\nconv2d_1/kernel:0: 70.00% sparsity  (103218/147456)\nbatch_normalization_1/gamma:0: 0.00% sparsity  (0/128)\nbatch_normalization_1/beta:0: 0.00% sparsity  (0/128)\nconv2d_2/kernel:0: 70.00% sparsity  (103218/147456)\nbatch_normalization_2/gamma:0: 0.00% sparsity  (0/128)\nbatch_normalization_2/beta:0: 0.00% sparsity  (0/128)\ndense/kernel:0: 70.02% sparsity  (717/1024)\ndense/bias:0: 0.00% sparsity  (0/8)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/fea5afa3-0195-4845-b5fc-b207c466a297","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":233},"deepnote_app_block_visible":true,"cell_id":"fe1b60a3a8604b3086c3b0faa149d172","deepnote_cell_type":"markdown"},"source":"# Test the model","block_group":"36e62aa17a6f40f3a813d4cf72f1cd03"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693930629922,"execution_millis":15068,"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":238},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"e9a59ebb2e1548cda8f8886227bc9c07","deepnote_cell_type":"code"},"source":"test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)","block_group":"665a8e506d0c44f68bbd8c6ab1dd363d","execution_count":null,"outputs":[{"name":"stdout","text":"40/40 [==============================] - 15s 367ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.8900\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/666f0d8d-d1a1-43cf-93ec-9a02f4fae91f","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693930644978,"execution_millis":18,"deepnote_app_coordinates":{"h":18,"w":12,"x":0,"y":244},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"178003531b414759ab7be3e25a5929ae","deepnote_cell_type":"code"},"source":"training_loss = history.history['loss'][-1]\ntraining_accuracy = history.history['sparse_categorical_accuracy'][-1]\nval_loss = history.history['val_loss'][-1]\nval_accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n\nprint(f'Training Loss: {training_loss:.4f}')\nprint(f'Training Accuracy: {training_accuracy*100.:.2f}%')\nprint()\nprint(f'Validation Loss: {val_loss:.4f}')\nprint(f'Validation Accuracy: {val_accuracy*100.:.2f}%')\nprint()\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy*100.:.2f}%')","block_group":"54e460161e41498686e613e1e14eb3d6","execution_count":null,"outputs":[{"name":"stdout","text":"Training Loss: 0.3044\nTraining Accuracy: 91.16%\n\nValidation Loss: 0.3840\nValidation Accuracy: 87.75%\n\nTest Loss: 0.3401\nTest Accuracy: 89.00%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/631aff48-46b1-472e-bdde-3ccba31c05b4","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":263},"deepnote_app_block_visible":true,"cell_id":"296f0dbe987642dea1ccd6dddec92330","deepnote_cell_type":"markdown"},"source":"# Save the Model","block_group":"74169c6fa8a0491bbfe443c65c7fc24e"},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":3,"w":12,"x":0,"y":268},"deepnote_app_block_visible":true,"cell_id":"59e8551e39b14813a7498d8b201fded1","deepnote_cell_type":"markdown"},"source":"### Save Keras Model","block_group":"764d532aae224e97abea490ebe58bd82"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693930644983,"execution_millis":1101,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":272},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"46080b1b4d8b49ee9b3cab13b73bc0af","deepnote_cell_type":"code"},"source":"import os\nfrom time import time\n\ntimestamp = int(time())\n\nmodel_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\nsaved_model_dir = f'./saved_models/{timestamp}'\nif not os.path.exists(saved_model_dir):\n    os.makedirs(saved_model_dir)\nmodel_for_export.save(saved_model_dir)","block_group":"d4fee4b5cd8443a899fd4eeef8f219d3","execution_count":null,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\nINFO:tensorflow:Assets written to: ./saved_models/1693930644/assets\nINFO:tensorflow:Assets written to: ./saved_models/1693930644/assets\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/84cd44a0-1d72-462b-bc6d-9fb74ca66509","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":3,"w":12,"x":0,"y":284},"deepnote_app_block_visible":true,"cell_id":"e5e6ba1bb8ea4dae9c771a20428fb444","deepnote_cell_type":"markdown"},"source":"### Save Hyper-Parameters and Results","block_group":"11b94afabad54895abef8fde875f4a74"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693930646067,"execution_millis":12,"deepnote_app_coordinates":{"h":12,"w":12,"x":0,"y":288},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"81f442b459604bfc99bc0789e72b4174","deepnote_cell_type":"code"},"source":"import pandas as pd\n\noutput_dict = {\n    'timestamp': timestamp,\n    **PREPROCESSING_ARGS,\n    **TRAINING_ARGS,\n    'final_sparsity': final_sparsity,\n    'test_accuracy': test_accuracy\n}\n\ndf = pd.DataFrame([output_dict])\n\noutput_path='./spectrogram_wp_results.csv'\ndf.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)","block_group":"792b64cb28fc4e4ea54fb4c313a24d49","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6f1fd91f-a434-4542-983d-3ce5ae14ac33' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2023-09-05T16:45:10.706Z"},"deepnote_app_comments_enabled":false,"deepnote_app_layout":"powerful-article","deepnote_app_execution_enabled":false,"deepnote_app_run_on_input_enabled":false,"deepnote_notebook_id":"7a736007f3cf4fabb93abcb9715c38bc","deepnote_execution_queue":[]}}