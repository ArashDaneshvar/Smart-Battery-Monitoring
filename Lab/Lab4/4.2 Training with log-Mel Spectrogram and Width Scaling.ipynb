{"cells":[{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927841043,"execution_millis":15,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":1},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":false,"deepnote_app_is_output_hidden":true,"cell_id":"05da947970d6484dbe281727824421f3","deepnote_cell_type":"code"},"source":"import tensorflow as tf","block_group":"48f0a25376a041a4b08116c5365fbdea","execution_count":null,"outputs":[{"name":"stderr","text":"2023-09-05 15:29:47.211783: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-09-05 15:29:47.271072: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-09-05 15:29:47.271881: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-09-05 15:29:48.482153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/0345a40e-342a-4b85-a007-a5a7eef3bfc6","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"30a8d6d497f04ad3a4be989937d98a30","deepnote_cell_type":"markdown"},"source":"# Define Hyper-Parameters","block_group":"e38b7716633d432389085edd3d64a7b8"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927842630,"execution_millis":10,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":29},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"54ae3c8b9e0e4feda3e68e3b724981bc","deepnote_cell_type":"code"},"source":"PREPROCESSING_ARGS = {\n    'sampling_rate': 16000,\n    'frame_length_in_s': 0.04,\n    'frame_step_in_s': 0.02,\n    'num_mel_bins': 40,\n    'lower_frequency': 20,\n    'upper_frequency': 4000,\n}\n\nTRAINING_ARGS = {\n    'batch_size': 20,\n    'initial_learning_rate': 0.01,\n    'end_learning_rate': 1.e-5,\n    'epochs': 10\n}\n\nalpha = 0.25","block_group":"947b4e4468a84dc3b482d43c20758fa3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":41},"deepnote_app_block_visible":true,"cell_id":"6a8be64756294f2fb260f32acd01c503","deepnote_cell_type":"markdown"},"source":"# Create Train/Val/Test Datasets","block_group":"920345a0189149bd8097d69fc6e147f6"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927848740,"execution_millis":408,"deepnote_app_coordinates":{"h":27,"w":12,"x":0,"y":46},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"86684cf511e94500896a6efe7d21db66","deepnote_cell_type":"code"},"source":"train_ds = tf.data.Dataset.list_files('msc-train/*')\nval_ds = tf.data.Dataset.list_files('msc-val/*')\ntest_ds = tf.data.Dataset.list_files('msc-test/*')","block_group":"1200c8e162384787b21ce053427193d8","execution_count":null,"outputs":[{"name":"stderr","text":"2022-11-11 14:52:07.483145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2022-11-11 14:52:07.483180: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2022-11-11 14:52:07.483196: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-bdbc19a1-4d38-4250-8aec-b2a48a575b76): /proc/driver/nvidia/version does not exist\n2022-11-11 14:52:07.483469: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-11 14:52:08.009751: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n2022-11-11 14:52:08.009985: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX2 AVX512F FMA\nWARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n2022-11-11 14:52:08.445739: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-11-11 14:52:08.447430: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n2022-11-11 14:52:08.447622: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at functional_ops.cc:373 : INTERNAL: No function library\n","output_type":"stream"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"TensorShape([49, 321])"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/393716d1-ab06-4caa-94a3-6452b041b279","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927854741,"execution_millis":680,"deepnote_app_coordinates":{"h":24,"w":12,"x":0,"y":74},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"2a842045ba64426c91877af023c811b5","deepnote_cell_type":"code"},"source":"from preprocessing import LABELS\nfrom preprocessing import AudioReader\nfrom preprocessing import MelSpectrogram\n\n\naudio_reader = AudioReader(tf.int16, 16000)\nmel_spec_processor = MelSpectrogram(**PREPROCESSING_ARGS)\n\ndef prepare_for_training(feature, label):\n    feature = tf.expand_dims(feature, -1)\n    label_id = tf.argmax(label == LABELS)\n\n    return feature, label_id\n\n\nbatch_size = TRAINING_ARGS['batch_size']\nepochs = TRAINING_ARGS['epochs']\n\ntrain_ds = (train_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mel_spec_processor.get_mel_spec_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size)\n            .cache())\nval_ds = (val_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mel_spec_processor.get_mel_spec_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size))\ntest_ds = (test_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(mel_spec_processor.get_mel_spec_and_label)\n            .map(prepare_for_training)\n            .batch(batch_size))","block_group":"47e91338d2b84037aa685e1bc8d67879","execution_count":null,"outputs":[{"name":"stderr","text":"2023-09-05 15:29:59.884693: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n2023-09-05 15:29:59.884857: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX AVX2 AVX512F FMA\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/2f25ffb9-0e15-4cc3-a013-122121c45418","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927857409,"execution_millis":496,"deepnote_app_coordinates":{"h":9,"w":12,"x":0,"y":99},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"b65f038a33a84cd8a0c81bfb9c1734ec","deepnote_cell_type":"code"},"source":"for example_batch, example_labels in train_ds.take(1):\n  print('Batch Shape:', example_batch.shape)\n  print('Data Shape:', example_batch.shape[1:])\n  print('Labels:', example_labels)","block_group":"a04bc62edefd40ca9741b9ccdc7f87d2","execution_count":null,"outputs":[{"name":"stdout","text":"Batch Shape: (20, 49, 40, 1)\nData Shape: (49, 40, 1)\nLabels: tf.Tensor([6 7 2 3 1 1 6 5 3 1 6 7 1 1 5 4 7 0 7 0], shape=(20,), dtype=int64)\n2023-09-05 15:30:57.823796: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/8fa1869f-f68b-4463-8e67-e7b74a1b7399","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":123},"deepnote_app_block_visible":true,"cell_id":"c762047f6bd443f791371fcfcf04b0a0","deepnote_cell_type":"markdown"},"source":"# Create the Model","block_group":"1485586e00ce4a9f8c35a0ca290cd72f"},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"06cc0adb6da64588a217bb15c15758da","deepnote_cell_type":"markdown"},"source":"\nConv2D(filters=128, kernel_size=[3, 3], stride=[2, 2], use_bias=False, padding=’valid’)\nBatchNormalization()\nReLU()\nConv2D(filters=128, kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding=’same’)\nBatchNormalization()\nReLU()\nConv2D(filters=128, kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding=’same’)\nBatchNormalization()\nReLU()\nGlobalAveragePooling2D()\nDense(units=8)\nSoftmax()\n","block_group":"c54430af9c5f46648cd633c5b52392e3"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927860029,"execution_millis":101,"deepnote_app_coordinates":{"h":13,"w":12,"x":0,"y":109},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"1a45aca6e49d48b9a86d462a2e508f5e","deepnote_cell_type":"code"},"source":"model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n    tf.keras.layers.Conv2D(filters=int(128 * alpha), kernel_size=[3, 3], strides=[2, 2], use_bias=False, padding='valid'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=int(128 * alpha), kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=int(128 * alpha), kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(units=len(LABELS)),\n    tf.keras.layers.Softmax()\n])","block_group":"6002dfe1157f4496b1a10c2bd80a9678","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927862412,"execution_millis":298,"deepnote_app_coordinates":{"h":27,"w":12,"x":0,"y":141},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"74cc90caf32c405bb2ef2fedabfec992","deepnote_cell_type":"code"},"source":"model.summary()","block_group":"c4e2afef40d2402990fdcc61499440f9","execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 24, 19, 32)        288       \n                                                                 \n batch_normalization (Batch  (None, 24, 19, 32)        128       \n Normalization)                                                  \n                                                                 \n re_lu (ReLU)                (None, 24, 19, 32)        0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 24, 19, 32)        9216      \n                                                                 \n batch_normalization_1 (Bat  (None, 24, 19, 32)        128       \n chNormalization)                                                \n                                                                 \n re_lu_1 (ReLU)              (None, 24, 19, 32)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 24, 19, 32)        9216      \n                                                                 \n batch_normalization_2 (Bat  (None, 24, 19, 32)        128       \n chNormalization)                                                \n                                                                 \n re_lu_2 (ReLU)              (None, 24, 19, 32)        0         \n                                                                 \n global_average_pooling2d (  (None, 32)                0         \n GlobalAveragePooling2D)                                         \n                                                                 \n dense (Dense)               (None, 8)                 264       \n                                                                 \n softmax (Softmax)           (None, 8)                 0         \n                                                                 \n=================================================================\nTotal params: 19368 (75.66 KB)\nTrainable params: 19176 (74.91 KB)\nNon-trainable params: 192 (768.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/68182fd4-6cbe-482b-b2eb-610cfb98cce1","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":169},"deepnote_app_block_visible":true,"cell_id":"21e1801b39f942e7a0d39f19aaa8aca4","deepnote_cell_type":"markdown"},"source":"# Train the Model","block_group":"1e51aa31e1634701bb268ec88dde9d5b"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693927866245,"execution_millis":453582,"deepnote_app_coordinates":{"h":29,"w":12,"x":0,"y":174},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"4f38d8d0ee484ee5ab396fbea23a81f7","deepnote_cell_type":"code"},"source":"loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\ninitial_learning_rate = TRAINING_ARGS['initial_learning_rate']\nend_learning_rate = TRAINING_ARGS['end_learning_rate']\n\nlinear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate=initial_learning_rate,\n    end_learning_rate=end_learning_rate,\n    decay_steps=len(train_ds) * epochs,\n)\noptimizer = tf.optimizers.Adam(learning_rate=linear_decay)\nmetrics = [tf.metrics.SparseCategoricalAccuracy()]\nmodel.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\nhistory = model.fit(train_ds, epochs=epochs, validation_data=val_ds)","block_group":"ca69a2c58a674425a4e79f5fab3239c7","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n320/320 [==============================] - 124s 383ms/step - loss: 1.9460 - sparse_categorical_accuracy: 0.2297 - val_loss: 2.3244 - val_sparse_categorical_accuracy: 0.1625\nEpoch 2/10\n320/320 [==============================] - 32s 101ms/step - loss: 1.5094 - sparse_categorical_accuracy: 0.4352 - val_loss: 1.2631 - val_sparse_categorical_accuracy: 0.5200\nEpoch 3/10\n320/320 [==============================] - 32s 101ms/step - loss: 1.0474 - sparse_categorical_accuracy: 0.6311 - val_loss: 1.3135 - val_sparse_categorical_accuracy: 0.4988\nEpoch 4/10\n320/320 [==============================] - 33s 103ms/step - loss: 0.7905 - sparse_categorical_accuracy: 0.7337 - val_loss: 1.1000 - val_sparse_categorical_accuracy: 0.6025\nEpoch 5/10\n320/320 [==============================] - 34s 108ms/step - loss: 0.6544 - sparse_categorical_accuracy: 0.7837 - val_loss: 0.8035 - val_sparse_categorical_accuracy: 0.7138\nEpoch 6/10\n320/320 [==============================] - 32s 101ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.7268 - val_sparse_categorical_accuracy: 0.7237\nEpoch 7/10\n320/320 [==============================] - 32s 100ms/step - loss: 0.5053 - sparse_categorical_accuracy: 0.8338 - val_loss: 0.5610 - val_sparse_categorical_accuracy: 0.8175\nEpoch 8/10\n320/320 [==============================] - 32s 100ms/step - loss: 0.4616 - sparse_categorical_accuracy: 0.8511 - val_loss: 0.5146 - val_sparse_categorical_accuracy: 0.8388\nEpoch 9/10\n320/320 [==============================] - 32s 100ms/step - loss: 0.4271 - sparse_categorical_accuracy: 0.8627 - val_loss: 0.5168 - val_sparse_categorical_accuracy: 0.8313\nEpoch 10/10\n320/320 [==============================] - 32s 100ms/step - loss: 0.4006 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.4528 - val_sparse_categorical_accuracy: 0.8625\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/406f576c-060f-44a8-acd9-48a77c03f5ce","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928319824,"execution_millis":310,"deepnote_app_coordinates":{"h":28,"w":12,"x":0,"y":204},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"bd3b38a035124ee4845e5c0adde5e2dd","deepnote_cell_type":"code"},"source":"history.history","block_group":"70381c1af43a4d0b865bf0473c82b008","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"{'loss': [1.9460313320159912,\n  1.5094166994094849,\n  1.047416090965271,\n  0.7904614210128784,\n  0.6544387936592102,\n  0.5634328722953796,\n  0.5053243041038513,\n  0.4616104066371918,\n  0.42705845832824707,\n  0.40061894059181213],\n 'sparse_categorical_accuracy': [0.22968749701976776,\n  0.4351562559604645,\n  0.6310937404632568,\n  0.7337499856948853,\n  0.7837499976158142,\n  0.8151562213897705,\n  0.8337500095367432,\n  0.8510937690734863,\n  0.8626562356948853,\n  0.8726562261581421],\n 'val_loss': [2.324437141418457,\n  1.263105034828186,\n  1.3135316371917725,\n  1.100049376487732,\n  0.8035047650337219,\n  0.7267595529556274,\n  0.5610030293464661,\n  0.5145642161369324,\n  0.5168039202690125,\n  0.4528101682662964],\n 'val_sparse_categorical_accuracy': [0.16249999403953552,\n  0.5199999809265137,\n  0.4987500011920929,\n  0.6025000214576721,\n  0.7137500047683716,\n  0.7237499952316284,\n  0.8174999952316284,\n  0.8387500047683716,\n  0.831250011920929,\n  0.862500011920929]}"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/b2fcc496-3a1e-4ecc-bb21-ff0970cade4a","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":233},"deepnote_app_block_visible":true,"cell_id":"e5e1578386864ed79e55a41b6d692c69","deepnote_cell_type":"markdown"},"source":"# Test the model","block_group":"0d1a8fe62e7d4aa9b4a11ecf07207282"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928319825,"execution_millis":11884,"deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":238},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"609263ba29284cb99fe2332cdae9ce8d","deepnote_cell_type":"code"},"source":"test_loss, test_accuracy = model.evaluate(test_ds)","block_group":"0807097af2b64e2e965047e6718b6860","execution_count":null,"outputs":[{"name":"stdout","text":"40/40 [==============================] - 12s 290ms/step - loss: 0.4057 - sparse_categorical_accuracy: 0.8838\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/a6193083-2f68-4e97-9c3e-f4bc039d07af","content_dependencies":null},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928331705,"execution_millis":20,"deepnote_app_coordinates":{"h":18,"w":12,"x":0,"y":244},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"82153ce6c2b1418a869ae9d7c1da6af7","deepnote_cell_type":"code"},"source":"training_loss = history.history['loss'][-1]\ntraining_accuracy = history.history['sparse_categorical_accuracy'][-1]\nval_loss = history.history['val_loss'][-1]\nval_accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n\nprint(f'Training Loss: {training_loss:.4f}')\nprint(f'Training Accuracy: {training_accuracy*100.:.2f}%')\nprint()\nprint(f'Validation Loss: {val_loss:.4f}')\nprint(f'Validation Accuracy: {val_accuracy*100.:.2f}%')\nprint()\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy*100.:.2f}%')","block_group":"2950ce4975d545c9a0b4a4872a17dc88","execution_count":null,"outputs":[{"name":"stdout","text":"Training Loss: 0.4006\nTraining Accuracy: 87.27%\n\nValidation Loss: 0.4528\nValidation Accuracy: 86.25%\n\nTest Loss: 0.4057\nTest Accuracy: 88.38%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/cd67bbe4-13ed-4e05-a7c6-08ca9c6827b3","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":4,"w":12,"x":0,"y":263},"deepnote_app_block_visible":true,"cell_id":"83974f5f74f840819bd36e51b453a913","deepnote_cell_type":"markdown"},"source":"# Save the Model","block_group":"7ccbd6d4f77741f09a6ea81c04038382"},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":3,"w":12,"x":0,"y":268},"deepnote_app_block_visible":true,"cell_id":"bcff5920c11c40fd87334edbf629ff37","deepnote_cell_type":"markdown"},"source":"### Save Keras Model","block_group":"8f050c3409724d49b622351ee1ed7ae5"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928331764,"execution_millis":1262,"deepnote_app_coordinates":{"h":11,"w":12,"x":0,"y":272},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"884345108f93471ebf57a26bac715b32","deepnote_cell_type":"code"},"source":"import os\nfrom time import time\n\ntimestamp = int(time())\n\nsaved_model_dir = f'./saved_models/{timestamp}'\nif not os.path.exists(saved_model_dir):\n    os.makedirs(saved_model_dir)\nmodel.save(saved_model_dir)","block_group":"b76d32e247ee4f27be3dcdefbba81e92","execution_count":null,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Assets written to: ./saved_models/1693928331/assets\nINFO:tensorflow:Assets written to: ./saved_models/1693928331/assets\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/7bf29761-b05f-4680-b6a5-c6f060653592","content_dependencies":null},{"cell_type":"markdown","metadata":{"tags":[],"deepnote_app_coordinates":{"h":3,"w":12,"x":0,"y":284},"deepnote_app_block_visible":true,"cell_id":"b876c3f6508a4b04ac945885fba5109a","deepnote_cell_type":"markdown"},"source":"### Save Hyper-Parameters and Results","block_group":"293dd1e60ef049a6afed7a2afdb55a61"},{"cell_type":"code","metadata":{"tags":[],"source_hash":null,"execution_start":1693928333006,"execution_millis":13,"deepnote_app_coordinates":{"h":12,"w":12,"x":0,"y":288},"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_output_hidden":true,"cell_id":"f515c274b6054fe5a0b2cf04f7db1075","deepnote_cell_type":"code"},"source":"import pandas as pd\n\noutput_dict = {\n    'timestamp': timestamp,\n    **PREPROCESSING_ARGS,\n    **TRAINING_ARGS,\n    'alpha': alpha,\n    'test_accuracy': test_accuracy\n}\n\ndf = pd.DataFrame([output_dict])\n\noutput_path='./spectrogram_ws_results.csv'\ndf.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)","block_group":"ae108285b2aa4515b2a91aa93fd5242c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6f1fd91f-a434-4542-983d-3ce5ae14ac33' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2023-09-05T16:45:10.698Z"},"deepnote_app_comments_enabled":false,"deepnote_app_layout":"powerful-article","deepnote_app_execution_enabled":false,"deepnote_app_run_on_input_enabled":false,"deepnote_notebook_id":"04c906159db94e989417f89898b4afd1","deepnote_execution_queue":[]}}