{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1a7c6662792f4e4384c41f964b9672fb","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3364,"execution_start":1703255139107,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-22 14:25:39.382590: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-12-22 14:25:39.458153: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-12-22 14:25:39.458943: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-22 14:25:41.151728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\n","Python version: OK\n","TensorFlow version: OK\n"]}],"source":["import sys\n","\n","\n","if sys.version.split()[0] != '3.10.12':\n","    print(sys.version)\n","    raise RuntimeError('Wrong Python version. Go to ENVIRONMENT settings, Stop machine, Start machine')\n","\n","\n","import tensorflow\n","if tensorflow.__version__ != '2.13.0':\n","    raise RuntimeError('Wrong TF version. Go to ENVIRONMENT settings, Stop machine, Start machine')\n","\n","\n","print('\\nPython version: OK')\n","print('TensorFlow version: OK')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"94abca4b1d3d4699b34fadfb005de0f0","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":14,"execution_start":1703255161000,"source_hash":null},"outputs":[],"source":["import tensorflow as tf\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6f1c4c6b3ace45c788544842e5add227","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":10,"execution_start":1703255163468,"source_hash":null},"outputs":[],"source":["PREPROCESSING_ARGS = {\n","    'sampling_rate': 16000,\n","    'frame_length_in_s': 0.032,\n","    'frame_step_in_s': 0.01,\n","    'num_mel_bins': 20,\n","    'lower_frequency': 20,\n","    'upper_frequency': 6000,\n","}\n","\n","TRAINING_ARGS = {\n","    'batch_size': 25,\n","    'initial_learning_rate': 0.01,\n","    'end_learning_rate': 1.e-5,\n","    'epochs': 80 # 10\n","}\n","final_sparsity = 0.85"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"a1860dbca88545db9b60a6f0586c2e92","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1703255166849,"source_hash":null},"outputs":[],"source":["train_ds = tf.data.Dataset.list_files('/tmp/yn-train/*')\n","test_ds = tf.data.Dataset.list_files('/tmp/yn-test/*')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c222173c2015410fbef88f77f451acd5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":9,"execution_start":1703255168848,"source_hash":null},"outputs":[],"source":["#import tensorflow as tf\n","\n","num_files = len(train_ds)\n","shuffled_train_ds = train_ds.shuffle(num_files, reshuffle_each_iteration=False)\n","\n","#train_ratio = 0.85\n","#num_train = int(train_ratio * num_files)\n","\n","#train_ds = train_dataset.take(num_train)\n","#val_ds = train_dataset.skip(num_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2ac97335b2d548d98b7494ae85653279","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":14,"execution_start":1703255173234,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set size 1600\n","Test set size 200\n"]}],"source":["print(f'Train set size {len(train_ds)}')\n","print(f'Test set size {len(test_ds)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0606117d428e44c9967eac0c344e7df4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":15,"execution_start":1703255175764,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(b'/tmp/yn-train/yes_106a6183_nohash_0.wav', shape=(), dtype=string)\n","tf.Tensor(b'/tmp/yn-train/yes_3b8406c0_nohash_0.wav', shape=(), dtype=string)\n","tf.Tensor(b'/tmp/yn-train/yes_ced4e2a1_nohash_0.wav', shape=(), dtype=string)\n","tf.Tensor(b'/tmp/yn-train/yes_73124b26_nohash_0.wav', shape=(), dtype=string)\n","tf.Tensor(b'/tmp/yn-train/no_d94eb94f_nohash_0.wav', shape=(), dtype=string)\n"]}],"source":["for x in train_ds.take(5):\n","    print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"dd7935dcb04b40708e6519deef29f720","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":726,"execution_start":1703255178919,"source_hash":null},"outputs":[],"source":["import preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4c4b14e13ebc4f978df5a8b263d0d75d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2993,"execution_start":1703255181251,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-22 14:26:22.115463: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX AVX2 FMA\n","2023-12-22 14:26:22.118354: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"]}],"source":["from preprocessing import LABELS\n","from preprocessing import AudioReader\n","from preprocessing import MelSpectrogram\n","\n","audio_reader = AudioReader(tf.int16, 16000)\n","mel_spec_processor = MelSpectrogram(**PREPROCESSING_ARGS)\n","\n","def prepare_for_training(feature, label):\n","    feature = tf.expand_dims(feature, -1)\n","    label_id = tf.argmax(label == LABELS)\n","\n","    return feature, label_id\n","\n","batch_size = TRAINING_ARGS['batch_size']\n","epochs = TRAINING_ARGS['epochs']\n","\n","train_ds = (train_ds\n","                .map(audio_reader.get_audio_and_label)\n","                .map(mel_spec_processor.get_mel_spec_and_label)\n","                .map(prepare_for_training)\n","                .batch(batch_size)\n","                .cache()\n","            )\n","#val_ds = (val_ds\n","#                .map(audio_reader.get_audio_and_label)\n","#                .map(mel_spec_processor.get_mel_spec_and_label)\n","#                .map(prepare_for_training)\n","#                .batch(batch_size)\n","#            )\n","test_ds = (test_ds\n","                .map(audio_reader.get_audio_and_label)\n","                .map(mel_spec_processor.get_mel_spec_and_label)\n","                .map(prepare_for_training)\n","                .batch(batch_size)\n","            )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"255c2d0a62d34f9abbf6ef122f07a299","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":330,"execution_start":1703255189745,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["(25, 97, 20, 1)\n","tf.Tensor([0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0], shape=(25,), dtype=int64)\n","2023-12-22 14:26:30.040219: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"]}],"source":["for example_batch, example_labels in train_ds.take(1):\n","    print(example_batch.shape),\n","    print(example_labels)"]},{"cell_type":"markdown","metadata":{"cell_id":"4bb4bee957fe4f5d80968a1c0e0f6256","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["Conv2D(filters=16, kernel_size=[3, 3], stride=[2, 2], use_bias=False, padding=’valid’)\n","BatchNormalization()\n","ReLU()\n","Conv2D(filters=16, kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding = 'same')\n","BatchNormalization()\n","ReLU()\n","Conv2D(filters=16, kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding = 'same')\n","BatchNormalization()\n","ReLU()\n","Conv2D(filters=16, kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding = 'same')\n","BatchNormalization()\n","ReLU()\n","GlobalAveragePooling2D()\n","Dense(len(LABELS))\n","Softmax()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c1f62632fb7c47cf8d875785d45e8604","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":293,"execution_start":1703255193781,"source_hash":null},"outputs":[],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n","    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[2, 2], use_bias=False, padding='valid'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.GlobalAveragePooling2D(),\n","    tf.keras.layers.Dense(len(LABELS)),\n","    tf.keras.layers.Softmax(), \n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f18f46007e774c859c6e9ce5d47f3372","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":179,"execution_start":1703255196702,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 48, 9, 16)         144       \n","                                                                 \n"," batch_normalization (Batch  (None, 48, 9, 16)         64        \n"," Normalization)                                                  \n","                                                                 \n"," re_lu (ReLU)                (None, 48, 9, 16)         0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 48, 9, 16)         2304      \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 48, 9, 16)         64        \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_1 (ReLU)              (None, 48, 9, 16)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 48, 9, 16)         2304      \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 48, 9, 16)         64        \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_2 (ReLU)              (None, 48, 9, 16)         0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 48, 9, 16)         2304      \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 48, 9, 16)         64        \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_3 (ReLU)              (None, 48, 9, 16)         0         \n","                                                                 \n"," global_average_pooling2d (  (None, 16)                0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n"," dense (Dense)               (None, 2)                 34        \n","                                                                 \n"," softmax (Softmax)           (None, 2)                 0         \n","                                                                 \n","=================================================================\n","Total params: 7346 (28.70 KB)\n","Trainable params: 7218 (28.20 KB)\n","Non-trainable params: 128 (512.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"34981bec4e0a4ad4b8026dfb6fa9fe8e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1612,"execution_start":1703255199807,"source_hash":null},"outputs":[],"source":["import tensorflow_model_optimization as tfmot\n","\n","prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","begin_step = int(len(train_ds) * epochs * 0.2)\n","end_step = int(len(train_ds) * epochs)\n","\n","pruning_params = {\n","    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n","        initial_sparsity=0.2,\n","        final_sparsity=final_sparsity,\n","        begin_step=begin_step,\n","        end_step=end_step\n","    )\n","}\n","\n","model_for_pruning = prune_low_magnitude(model, **pruning_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"56874dc5579c404192485777e4b8070f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":168,"execution_start":1703255203485,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," prune_low_magnitude_conv2d  (None, 48, 9, 16)         290       \n","  (PruneLowMagnitude)                                            \n","                                                                 \n"," prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n"," normalization (PruneLowMag                                      \n"," nitude)                                                         \n","                                                                 \n"," prune_low_magnitude_re_lu   (None, 48, 9, 16)         1         \n"," (PruneLowMagnitude)                                             \n","                                                                 \n"," prune_low_magnitude_conv2d  (None, 48, 9, 16)         4610      \n"," _1 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n"," normalization_1 (PruneLowM                                      \n"," agnitude)                                                       \n","                                                                 \n"," prune_low_magnitude_re_lu_  (None, 48, 9, 16)         1         \n"," 1 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_conv2d  (None, 48, 9, 16)         4610      \n"," _2 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n"," normalization_2 (PruneLowM                                      \n"," agnitude)                                                       \n","                                                                 \n"," prune_low_magnitude_re_lu_  (None, 48, 9, 16)         1         \n"," 2 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_conv2d  (None, 48, 9, 16)         4610      \n"," _3 (PruneLowMagnitude)                                          \n","                                                                 \n"," prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n"," normalization_3 (PruneLowM                                      \n"," agnitude)                                                       \n","                                                                 \n"," prune_low_magnitude_re_lu_  (None, 48, 9, 16)         1         \n"," 3 (PruneLowMagnitude)                                           \n","                                                                 \n"," prune_low_magnitude_global  (None, 16)                1         \n"," _average_pooling2d (PruneL                                      \n"," owMagnitude)                                                    \n","                                                                 \n"," prune_low_magnitude_dense   (None, 2)                 68        \n"," (PruneLowMagnitude)                                             \n","                                                                 \n"," prune_low_magnitude_softma  (None, 2)                 1         \n"," x (PruneLowMagnitude)                                           \n","                                                                 \n","=================================================================\n","Total params: 14454 (56.52 KB)\n","Trainable params: 7218 (28.20 KB)\n","Non-trainable params: 7236 (28.32 KB)\n","_________________________________________________________________\n"]}],"source":["model_for_pruning.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"81d6d2fa36584f2891161401e7628b44","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":412844,"execution_start":1703256438234,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/80\n","64/64 [==============================] - 10s 81ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9981\n","Epoch 2/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0262 - sparse_categorical_accuracy: 0.9912\n","Epoch 3/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9887\n","Epoch 4/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9962\n","Epoch 5/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9962\n","Epoch 6/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9981\n","Epoch 7/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9987\n","Epoch 8/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n","Epoch 9/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n","Epoch 10/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n","Epoch 11/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n","Epoch 12/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987\n","Epoch 13/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987\n","Epoch 14/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n","Epoch 15/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9987\n","Epoch 16/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9987\n","Epoch 17/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9987\n","Epoch 18/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9987\n","Epoch 19/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9987\n","Epoch 20/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9987\n","Epoch 21/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0030 - sparse_categorical_accuracy: 0.9987\n","Epoch 22/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9987\n","Epoch 23/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9987\n","Epoch 24/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9987\n","Epoch 25/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9987\n","Epoch 26/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9987\n","Epoch 27/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9987\n","Epoch 28/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9987\n","Epoch 29/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9987\n","Epoch 30/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9987\n","Epoch 31/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9987\n","Epoch 32/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9987\n","Epoch 33/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9987\n","Epoch 34/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9987\n","Epoch 35/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9987\n","Epoch 36/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9987\n","Epoch 37/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9987\n","Epoch 38/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9987\n","Epoch 39/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9987\n","Epoch 40/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9987\n","Epoch 41/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9987\n","Epoch 42/80\n","64/64 [==============================] - 5s 76ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9987\n","Epoch 43/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9987\n","Epoch 44/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9987\n","Epoch 45/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9987\n","Epoch 46/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9987\n","Epoch 47/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9987\n","Epoch 48/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9987\n","Epoch 49/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9987\n","Epoch 50/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9987\n","Epoch 51/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9987\n","Epoch 52/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9987\n","Epoch 53/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9987\n","Epoch 54/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9962\n","Epoch 55/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.9944\n","Epoch 56/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9937\n","Epoch 57/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987\n","Epoch 58/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9987\n","Epoch 59/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9994\n","Epoch 60/80\n","64/64 [==============================] - 5s 75ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9994\n","Epoch 61/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9994\n","Epoch 62/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9994\n","Epoch 63/80\n","64/64 [==============================] - 5s 77ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9987\n","Epoch 64/80\n","64/64 [==============================] - 5s 77ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9987\n","Epoch 65/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9987\n","Epoch 66/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9987\n","Epoch 67/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9987\n","Epoch 68/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9994\n","Epoch 69/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9994\n","Epoch 70/80\n","64/64 [==============================] - 5s 81ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9994\n","Epoch 71/80\n","64/64 [==============================] - 5s 80ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9994\n","Epoch 72/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9994\n","Epoch 73/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9994\n","Epoch 74/80\n","64/64 [==============================] - 5s 77ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9994\n","Epoch 75/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9994\n","Epoch 76/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9994\n","Epoch 77/80\n","64/64 [==============================] - 5s 77ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9994\n","Epoch 78/80\n","64/64 [==============================] - 5s 77ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9994\n","Epoch 79/80\n","64/64 [==============================] - 5s 78ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9994\n","Epoch 80/80\n","64/64 [==============================] - 5s 79ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9994\n"]}],"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n","initial_learning_rate = TRAINING_ARGS['initial_learning_rate']\n","end_learning_rate = TRAINING_ARGS['end_learning_rate']\n","\n","lr_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n","    initial_learning_rate,\n","    len(train_ds) * epochs,\n","    end_learning_rate,\n",")\n","optimizer = tf.optimizers.Adam(learning_rate=lr_decay)\n","metrics = [tf.metrics.SparseCategoricalAccuracy()]\n","callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n","model_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","\n","history = model_for_pruning.fit(train_ds, epochs=epochs, callbacks=callbacks)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4ac1aaaa97ed40939620ee958ba522ba","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8,"execution_start":1703257063319,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["conv2d/kernel:0: 84.72% sparsity (122/144)\n","batch_normalization/gamma:0: 0.00% sparsity (0/16)\n","batch_normalization/beta:0: 0.00% sparsity (0/16)\n","conv2d_1/kernel:0: 84.98% sparsity (1958/2304)\n","batch_normalization_1/gamma:0: 0.00% sparsity (0/16)\n","batch_normalization_1/beta:0: 0.00% sparsity (0/16)\n","conv2d_2/kernel:0: 84.98% sparsity (1958/2304)\n","batch_normalization_2/gamma:0: 0.00% sparsity (0/16)\n","batch_normalization_2/beta:0: 0.00% sparsity (0/16)\n","conv2d_3/kernel:0: 84.98% sparsity (1958/2304)\n","batch_normalization_3/gamma:0: 0.00% sparsity (0/16)\n","batch_normalization_3/beta:0: 0.00% sparsity (0/16)\n","dense/kernel:0: 84.38% sparsity (27/32)\n","dense/bias:0: 0.00% sparsity (0/2)\n"]}],"source":["import numpy as np\n","\n","for layer in model_for_pruning.layers:\n","    if isinstance(layer, tf.keras.layers.Wrapper):\n","        weights = layer.trainable_weights\n","    else:\n","        weights = layer.weights\n","    for weight in weights:\n","        weight_size = weight.numpy().size\n","        zero_num = np.count_nonzero(weight == 0)\n","        print(f'{weight.name}: {zero_num/weight_size:.2%} sparsity',\n","              f'({zero_num}/{weight_size})'\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"cc29a43d73c84efbbe27968daf42b920","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1241,"execution_start":1703257066603,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 1s 97ms/step - loss: 0.0266 - sparse_categorical_accuracy: 0.9900\n","0.02657555602490902 0.9900000095367432\n"]}],"source":["test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)\n","print(test_loss, test_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"b9f7cc32badf4bcf97bfaea3e280268e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1703257068655,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Loss: 0.0014\n","Training Accuracy: 99.94%\n","\n","Test Loss: 0.0266\n","Test Accuracy: 99.00%\n"]}],"source":["training_loss = history.history['loss'][-1]\n","training_accuracy = history.history['sparse_categorical_accuracy'][-1]\n","#val_loss = history.history['val_loss'][-1]\n","#val_accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n","\n","print(f'Training Loss: {training_loss:.4f}')\n","print(f'Training Accuracy: {training_accuracy*100.:.2f}%')\n","print()\n","#print(f'Validation Loss: {val_loss:.4f}')\n","#print(f'Validation Accuracy: {val_accuracy*100.:.2f}%')\n","#print()\n","print(f'Test Loss: {test_loss:.4f}')\n","print(f'Test Accuracy: {test_accuracy*100.:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"1580b4ecaf7a4db0b3c0411cdf8b988b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7190,"execution_start":1703257074741,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: ./saved_models_lorenzo/1703257074/assets\n","INFO:tensorflow:Assets written to: ./saved_models_lorenzo/1703257074/assets\n","Original tf size (pruned model): 0.000 KB\n"]}],"source":["import os\n","import time\n","\n","timestamp = int(time.time())\n","\n","save_model_dir = f'./saved_models/{timestamp}'\n","model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","\n","if not os.path.exists(save_model_dir):\n","    os.makedirs(save_model_dir)\n","\n","model_for_export.save(save_model_dir)\n","tf_size = os.path.getsize(save_model_dir) / 1024\n","print(f'Original tf size (pruned model): {tf_size:.3f} KB')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2894b36c08e0417fb4eec6b31e6e6dea","deepnote_cell_type":"code"},"outputs":[],"source":["!ls saved_models"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"7cf7a1af1b15467d8d8f2dcbcb5ae4fe","deepnote_cell_type":"code"},"outputs":[],"source":["MODEL_NAME = 'model13'"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"48c646c4340c455dbb896dad39aa8cfe","deepnote_cell_type":"code"},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_saved_model(f'./saved_models/{MODEL_NAME}')\n","converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n","tflite_model = converter.convert()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8c761d3919264d8ea8bc83c83473085f","deepnote_cell_type":"code"},"outputs":[],"source":["tflite_models_dir = './tflite_models'\n","if not os.path.exists(tflite_models_dir):\n","    os.makedirs(tflite_models_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f55a7b7156884187b7889b257b32a698","deepnote_cell_type":"code"},"outputs":[],"source":["tflite_model_name = os.path.join(tflite_models_dir, f'{MODEL_NAME}.tflite')\n","tflite_model_name"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f08b1a3b11ff4d4d809b6f847ef59365","deepnote_cell_type":"code"},"outputs":[],"source":["with open(tflite_model_name, 'wb') as fp:\n","    fp.write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"b313982d42bd414a942387c9613e6a23","deepnote_cell_type":"code"},"outputs":[],"source":["!ls tflite_models"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0052841049fd4baba9f0a28105045e9c","deepnote_cell_type":"code"},"outputs":[],"source":["import zipfile\n","\n","with zipfile.ZipFile(f'{tflite_model_name}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(tflite_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2246c13839f64c08b41b4210870d4874","deepnote_cell_type":"code"},"outputs":[],"source":["tflite_size = os.path.getsize(tflite_model_name) / 1024.0\n","zipped_size = os.path.getsize(f'{tflite_model_name}.zip') / 1024.0\n","\n","print(f'Original tflite size (pruned model): {tflite_size:.3f} KB')\n","print(f'Zipped tflite size (pruned model): {zipped_size:.3f} KB')"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=1b0b0df8-8392-4edb-9f9f-6f8029fb1a2c' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"8a69dee099c84b3baa03bc119b235e56","deepnote_persisted_session":{"createdAt":"2023-12-22T15:30:18.747Z"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
